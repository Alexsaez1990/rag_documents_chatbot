{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = config['API_KEYS']['huggingface_token']\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# Load pdf\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "########## To load a list of pdfs ##########\n",
    "\n",
    "# from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# loader=PyPDFDirectoryLoader(\"./us_census\")\n",
    "\n",
    "############################################\n",
    "\n",
    "file_path = \"C:/Users/Asus/Downloads/Informe_Tecnico_InstrumentoFortalecePYME.pdf\"\n",
    "\n",
    "loader = PyMuPDFLoader(file_path=file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "# Make splits\n",
    "\n",
    "from langchain_text_splitters import  RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(all_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={'device':'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings':True}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "# Could try with Chroma\n",
    "\n",
    "vector_store = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n",
    "\n",
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "################################################### VOY POR EL 23:20 DEL VIDEO RAG DEL INDIO #########################################\n",
    "\n",
    "\n",
    "# LLM Model to QA\n",
    "#model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model_name = \"EleutherAI/gpt-neo-1.3B\"\n",
    "#model_name = \"t5-small\"\n",
    "model_name = \"gpt2\"\n",
    "\n",
    "# Depending on task, objective can be one or other. Different models are better for one or other task\n",
    "#objective = \"text-generation\"  # text-generation is more open-ended responses or more detailed anwsers based on the context\n",
    "#objective = \"question-answering\" # question-answering extract anwsers from the provided context (a document for example). Factual.\n",
    "#hf_pipeline = pipeline(objective, model=model_name, tokenizer=model_name, device=0) # Device=0 to GPU\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "hf = HuggingFaceHub(\n",
    "    repo_id=model_name,\n",
    "    model_kwargs={\"temperature\":0.4, \"max_length\":100}\n",
    ")\n",
    "\n",
    "#llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "def ask_question2(hf, question: str):\n",
    "    #docs = vector_store.similarity_search(question)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k':3})\n",
    "\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    hf.invoke(question)\n",
    "\n",
    "    prompt_template=\"\"\"\n",
    "    Contexto relevante:\n",
    "    {context}\n",
    "\n",
    "    Pregunta: \n",
    "    {question}\n",
    "\n",
    "    Respuesta concisa y precisa:\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    retrievalQA = RetrievalQA.from_chain_type(\n",
    "        llm=hf,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        verbose=True,\n",
    "        #return_source_document=True,\n",
    "        chain_type_kwargs={\"prompt\":prompt}\n",
    "    )\n",
    "\n",
    "    #result = retrievalQA.invoke({\"query\": question})\n",
    "    result = retrievalQA.run(question)\n",
    "    return result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs_content: 23 \n",
      " \n",
      " \n",
      " \n",
      "Figura 1. Diagrama Modelo Appelfeller y Feldmann (2018).\n",
      "\n",
      "23 \n",
      " \n",
      " \n",
      " \n",
      "Figura 1. Diagrama Modelo Appelfeller y Feldmann (2018).\n",
      "\n",
      "23 \n",
      " \n",
      " \n",
      "Figura 2. Primera página informe de diagnóstico.  \n",
      " \n",
      "5.2. Resumen ejecutivo \n",
      " \n",
      "En segundo lugar, el informe presenta un resumen ejecutivo que describe los alcances del \n",
      "programa Fortalece Pyme de la Región de Antofagasta. Luego, continúa con  una reflexión \n",
      "sobre la importancia de la digitalización de las empresas. Finalmente presenta una breve \n",
      "explicación sobre la evaluación de las dimensiones de la digitalización. En la Figura 3 muestra \n",
      "la segunda página del informe automatizado.\n",
      "\n",
      "    Contexto relevante:\n",
      "    23 \n",
      " \n",
      " \n",
      " \n",
      "Figura 1. Diagrama Modelo Appelfeller y Feldmann (2018).\n",
      "\n",
      "23 \n",
      " \n",
      " \n",
      " \n",
      "Figura 1. Diagrama Modelo Appelfeller y Feldmann (2018).\n",
      "\n",
      "23 \n",
      " \n",
      " \n",
      "Figura 2. Primera página informe de diagnóstico.  \n",
      " \n",
      "5.2. Resumen ejecutivo \n",
      " \n",
      "En segundo lugar, el informe presenta un resumen ejecutivo que describe los alcances del \n",
      "programa Fortalece Pyme de la Región de Antofagasta. Luego, continúa con  una reflexión \n",
      "sobre la importancia de la digitalización de las empresas. Finalmente presenta una breve \n",
      "explicación sobre la evaluación de las dimensiones de la digitalización. En la Figura 3 muestra \n",
      "la segunda página del informe automatizado.\n",
      "\n",
      "    Pregunta: \n",
      "    Dame una  lista de las 2 ideas más importantes del texto\n",
      "\n",
      "    Respuesta concisa y precisa:\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la textouously:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "Más importantes de la texto:\n",
      "\n",
      "    \n",
      "\n",
      "M atal\n"
     ]
    }
   ],
   "source": [
    "question = \"Dame una  lista de las 2 ideas más importantes del texto\"\n",
    "answer = ask_question2(hf=hf, question=question)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"¿De qué no habla el texto?\"\n",
    "answer2 = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
